{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af02ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install sentence-transformers numpy scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af71a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764a6656",
   "metadata": {},
   "source": [
    "## Sample Document Collection\n",
    "\n",
    "Creating a knowledge base with documents about machine learning topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68896983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample documents (knowledge base)\n",
    "documents = [\n",
    "    \"Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data.\",\n",
    "    \"Deep learning uses neural networks with multiple layers to learn hierarchical representations of data.\",\n",
    "    \"Natural language processing enables computers to understand, interpret, and generate human language.\",\n",
    "    \"Computer vision allows machines to interpret and understand visual information from the world.\",\n",
    "    \"Reinforcement learning trains agents to make decisions by rewarding desired behaviors.\",\n",
    "    \"Supervised learning uses labeled data to train models that can make predictions on new data.\",\n",
    "    \"Unsupervised learning discovers patterns in data without explicit labels or supervision.\",\n",
    "    \"Transfer learning leverages knowledge from pre-trained models to solve new related tasks.\",\n",
    "    \"Neural networks are computing systems inspired by biological neural networks in animal brains.\",\n",
    "    \"Gradient descent is an optimization algorithm used to minimize loss functions in machine learning.\",\n",
    "    \"Overfitting occurs when a model learns the training data too well and fails to generalize.\",\n",
    "    \"Cross-validation is a technique to assess model performance by splitting data into train and test sets.\",\n",
    "    \"Feature engineering involves creating new features from raw data to improve model performance.\",\n",
    "    \"Ensemble methods combine multiple models to produce better predictions than individual models.\",\n",
    "    \"Convolutional neural networks are specialized for processing grid-like data such as images.\",\n",
    "]\n",
    "\n",
    "print(f\"Knowledge base contains {len(documents)} documents\\n\")\n",
    "print(\"Sample documents:\")\n",
    "for i, doc in enumerate(documents[:3]):\n",
    "    print(f\"{i+1}. {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ba452",
   "metadata": {},
   "source": [
    "## Text Chunking and Preparation\n",
    "\n",
    "Organizing documents into a structured format for retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b990c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create structured document database\n",
    "doc_database = pd.DataFrame({\n",
    "    'doc_id': range(len(documents)),\n",
    "    'content': documents\n",
    "})\n",
    "\n",
    "print(\"Document Database:\")\n",
    "print(doc_database.head(10))\n",
    "print(f\"\\nTotal documents: {len(doc_database)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d28d7d",
   "metadata": {},
   "source": [
    "## Embedding Generation\n",
    "\n",
    "Using SentenceTransformer to convert documents into dense vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7e6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding model\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "print(f\"Loading embedding model: {MODEL_NAME}\")\n",
    "embedding_model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "print(f\"Model loaded successfully\")\n",
    "print(f\"Embedding dimension: {embedding_model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd5b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all documents\n",
    "print(\"Generating embeddings for documents...\")\n",
    "doc_embeddings = embedding_model.encode(documents, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\nEmbeddings shape: {doc_embeddings.shape}\")\n",
    "print(f\"Each document is represented as a {doc_embeddings.shape[1]}-dimensional vector\")\n",
    "\n",
    "# Add embeddings to database\n",
    "doc_database['embedding'] = list(doc_embeddings)\n",
    "print(\"\\nEmbeddings added to database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38221b0e",
   "metadata": {},
   "source": [
    "## Cosine Similarity Retrieval\n",
    "\n",
    "Implementing retrieval function to find most relevant documents for a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e973d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Retrieve most relevant documents for a query using cosine similarity\n",
    "    \n",
    "    Args:\n",
    "        query: Search query string\n",
    "        top_k: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with retrieved documents and similarity scores\n",
    "    \"\"\"\n",
    "    # Generate query embedding\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    \n",
    "    # Calculate cosine similarity between query and all documents\n",
    "    similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "    \n",
    "    # Get top-k most similar documents\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results = pd.DataFrame({\n",
    "        'rank': range(1, top_k + 1),\n",
    "        'doc_id': top_indices,\n",
    "        'similarity': similarities[top_indices],\n",
    "        'content': [documents[i] for i in top_indices]\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"Retrieval function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ab580c",
   "metadata": {},
   "source": [
    "## Testing Retrieval System\n",
    "\n",
    "Running queries to test document retrieval effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94526009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Query 1\n",
    "query_1 = \"How do neural networks work?\"\n",
    "\n",
    "print(f\"Query: {query_1}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_1 = retrieve_documents(query_1, top_k=3)\n",
    "\n",
    "print(\"\\nTop 3 Retrieved Documents:\")\n",
    "for _, row in results_1.iterrows():\n",
    "    print(f\"\\nRank {row['rank']} (Similarity: {row['similarity']:.4f})\")\n",
    "    print(f\"  {row['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c974b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Query 2\n",
    "query_2 = \"What is the difference between supervised and unsupervised learning?\"\n",
    "\n",
    "print(f\"Query: {query_2}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_2 = retrieve_documents(query_2, top_k=3)\n",
    "\n",
    "print(\"\\nTop 3 Retrieved Documents:\")\n",
    "for _, row in results_2.iterrows():\n",
    "    print(f\"\\nRank {row['rank']} (Similarity: {row['similarity']:.4f})\")\n",
    "    print(f\"  {row['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9dec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Query 3\n",
    "query_3 = \"Explain computer vision applications\"\n",
    "\n",
    "print(f\"Query: {query_3}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results_3 = retrieve_documents(query_3, top_k=3)\n",
    "\n",
    "print(\"\\nTop 3 Retrieved Documents:\")\n",
    "for _, row in results_3.iterrows():\n",
    "    print(f\"\\nRank {row['rank']} (Similarity: {row['similarity']:.4f})\")\n",
    "    print(f\"  {row['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa1a01d",
   "metadata": {},
   "source": [
    "## Similarity Analysis\n",
    "\n",
    "Visualizing similarity scores across different queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb7a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Analyze similarity distributions for different queries\n",
    "test_queries = [\n",
    "    \"How do neural networks work?\",\n",
    "    \"What is supervised learning?\",\n",
    "    \"Explain computer vision\",\n",
    "    \"What is feature engineering?\"\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, query in enumerate(test_queries):\n",
    "    # Get embeddings\n",
    "    query_emb = embedding_model.encode([query])\n",
    "    similarities = cosine_similarity(query_emb, doc_embeddings)[0]\n",
    "    \n",
    "    # Sort for visualization\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    sorted_similarities = similarities[sorted_indices]\n",
    "    \n",
    "    # Plot\n",
    "    axes[idx].bar(range(len(similarities)), sorted_similarities, color='steelblue', alpha=0.7)\n",
    "    axes[idx].axhline(y=0.3, color='red', linestyle='--', alpha=0.5, label='Threshold')\n",
    "    axes[idx].set_title(f'Query: \"{query[:40]}...\"', fontsize=10, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Document Rank')\n",
    "    axes[idx].set_ylabel('Cosine Similarity')\n",
    "    axes[idx].grid(alpha=0.3, axis='y')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7eb0a2",
   "metadata": {},
   "source": [
    "## Context-Based Answer Generation\n",
    "\n",
    "Simulating answer generation using retrieved context (without LLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da41e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Generate answer by retrieving relevant context\n",
    "    \n",
    "    Args:\n",
    "        query: User question\n",
    "        top_k: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with query, retrieved context, and summary\n",
    "    \"\"\"\n",
    "    # Retrieve relevant documents\n",
    "    results = retrieve_documents(query, top_k)\n",
    "    \n",
    "    # Combine retrieved documents as context\n",
    "    context = \"\\n\\n\".join([f\"[{i+1}] {row['content']}\" \n",
    "                           for i, (_, row) in enumerate(results.iterrows())])\n",
    "    \n",
    "    # Calculate average similarity\n",
    "    avg_similarity = results['similarity'].mean()\n",
    "    \n",
    "    return {\n",
    "        'query': query,\n",
    "        'context': context,\n",
    "        'num_docs': len(results),\n",
    "        'avg_similarity': avg_similarity,\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "print(\"Answer generation function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad90c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate answer for a query\n",
    "query = \"What techniques help prevent overfitting in machine learning models?\"\n",
    "\n",
    "answer_data = generate_answer(query, top_k=4)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"QUERY:\")\n",
    "print(answer_data['query'])\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RETRIEVED CONTEXT:\")\n",
    "print(answer_data['context'])\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"METADATA:\")\n",
    "print(f\"  Documents Retrieved: {answer_data['num_docs']}\")\n",
    "print(f\"  Average Similarity: {answer_data['avg_similarity']:.4f}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SIMILARITY SCORES:\")\n",
    "for _, row in answer_data['results'].iterrows():\n",
    "    print(f\"  Doc {row['doc_id']}: {row['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269b7dd0",
   "metadata": {},
   "source": [
    "## Interactive Query System\n",
    "\n",
    "Simple interface for querying the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d45828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_query(query, top_k=3, show_scores=True):\n",
    "    \"\"\"Interactive query interface\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    results = retrieve_documents(query, top_k)\n",
    "    \n",
    "    print(f\"\\nRetrieved {len(results)} most relevant documents:\\n\")\n",
    "    \n",
    "    for _, row in results.iterrows():\n",
    "        print(f\"ðŸ“„ Rank {row['rank']}\")\n",
    "        if show_scores:\n",
    "            print(f\"   Similarity: {row['similarity']:.4f}\")\n",
    "        print(f\"   Content: {row['content']}\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test interactive system\n",
    "test_queries = [\n",
    "    \"What is transfer learning?\",\n",
    "    \"How does gradient descent optimize models?\",\n",
    "    \"What are ensemble methods?\"\n",
    "]\n",
    "\n",
    "for test_query in test_queries:\n",
    "    interactive_query(test_query, top_k=2)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd951a7",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Analyzing retrieval quality and similarity distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495bc8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics across multiple queries\n",
    "evaluation_queries = [\n",
    "    \"neural networks architecture\",\n",
    "    \"supervised vs unsupervised learning\",\n",
    "    \"deep learning methods\",\n",
    "    \"model evaluation techniques\",\n",
    "    \"optimization algorithms\"\n",
    "]\n",
    "\n",
    "stats = []\n",
    "\n",
    "for query in evaluation_queries:\n",
    "    results = retrieve_documents(query, top_k=5)\n",
    "    stats.append({\n",
    "        'query': query,\n",
    "        'max_similarity': results['similarity'].max(),\n",
    "        'mean_similarity': results['similarity'].mean(),\n",
    "        'min_similarity': results['similarity'].min(),\n",
    "        'std_similarity': results['similarity'].std()\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(stats)\n",
    "\n",
    "print(\"Retrieval Quality Statistics:\")\n",
    "print(\"=\" * 80)\n",
    "print(stats_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Overall Statistics:\")\n",
    "print(f\"  Average Max Similarity: {stats_df['max_similarity'].mean():.4f}\")\n",
    "print(f\"  Average Mean Similarity: {stats_df['mean_similarity'].mean():.4f}\")\n",
    "print(f\"  Average Std Similarity: {stats_df['std_similarity'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b39d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize overall performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Box plot of similarities\n",
    "data_to_plot = [stats_df['max_similarity'], stats_df['mean_similarity'], stats_df['min_similarity']]\n",
    "axes[0].boxplot(data_to_plot, labels=['Max', 'Mean', 'Min'])\n",
    "axes[0].set_title('Similarity Score Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Cosine Similarity')\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# Bar chart of average metrics\n",
    "metrics = ['Max', 'Mean', 'Min']\n",
    "values = [stats_df['max_similarity'].mean(), \n",
    "          stats_df['mean_similarity'].mean(), \n",
    "          stats_df['min_similarity'].mean()]\n",
    "\n",
    "axes[1].bar(metrics, values, color=['green', 'blue', 'orange'], alpha=0.7)\n",
    "axes[1].set_title('Average Similarity Metrics', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Cosine Similarity')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "for i, v in enumerate(values):\n",
    "    axes[1].text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
